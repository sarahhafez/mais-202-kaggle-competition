# -*- coding: utf-8 -*-
"""FashionItems.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mnTY954CYtp035KafRCYFmfGQtqCKgnE
"""

#downloading the files from kaggle
!pip install kaggle
!mkdir ~/.kaggle
!cp drive/"My Drive"/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c winter2020-mais-202

!unzip train_images.npy.zip
!unzip test_images.npy.zip

import numpy as np
train_images = np.load("train_images.npy")
train_images = np.expand_dims(train_images, axis=3)

import matplotlib.pyplot as plt

def show_image(arr):
    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)
    plt.imshow(two_d, interpolation='nearest')
    plt.show()

show_image(train_images[75]) # 0 is the index of the training image you want to display

import pandas as pd
train_labels = pd.read_csv('train_labels.csv')

#getting the training labels as an array
print(train_labels['label'])
train_labels1= train_labels['label'].tolist()
train_labels2 = np.array(train_labels1)
print(train_labels2)

mean = train_images.mean(axis=0)
std = train_images.std(axis=0)

train_images = (train_images - mean) /std

show_image(train_images[1])

import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
model = Sequential()


model = Sequential([
    Conv2D(filters = 8, kernel_size=(3, 3), activation='relu',padding='same',input_shape=(28, 28, 1)),
    Dropout(0.5),
    Conv2D(filters = 8, kernel_size=(3, 3), activation='relu'),
    Dropout(0.5),
    
    MaxPooling2D(pool_size=(2, 2),strides=4),
    
    Flatten(),
    
    Dense(256, activation='relu'),
    Dropout(0.05),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dropout(0.05),
    Dense(32, activation='relu'),
    Dense(10, activation='softmax')
  
  
])

#literally compiles the model, u have to run after any changes in the model
model.compile(
  'adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)

from keras.utils import to_categorical
model.fit(
  train_images,
  to_categorical(train_labels2),
  epochs=50, #how many reruns it will do 50 can get u up to 98%,
)

model.save_weights('cnn5.h5') #saves the model if u dont plan on retraining it

test_images = np.load("test_images.npy")
test_images = np.expand_dims(test_images, axis=3)

mean = test_images.mean(axis=0)
std = test_images.std(axis=0)

test_images = (test_images - mean) /std

predictions = model.predict(test_images)
readable_predictions = np.argmax(predictions, axis=1)

print(readable_predictions)

ID = []
for i in range(20000):
    ID.append(i)

#create the submission csv
df = pd.DataFrame(data = readable_predictions, columns = ["label"])
df['ID'] = ID
df = df[['ID','label']]
print(df)

df.to_csv('cnn7.csv', index=False)

readable_predictions[8]

